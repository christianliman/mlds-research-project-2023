{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f5f0dbaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import copy\n",
    "import shap\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy.special import expit\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from matplotlib import cm\n",
    "from sklearn.base import TransformerMixin, ClassifierMixin\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "616ee793",
   "metadata": {},
   "source": [
    "## Step 1: Load incomplete dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93df51ed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a57150d2",
   "metadata": {},
   "source": [
    "## Step 2: Implement multiple imputation with PMM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dfadb3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ImputeRandomSample(data, seed=None):\n",
    "    \"\"\"\n",
    "    Impute missing values using one of the observed values for a given variable \n",
    "    (univariate imputation).\n",
    "    This function iterates over all columns in a data frame and imputes as necessary.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Pandas DataFrame\n",
    "        Data frame to be imputed\n",
    "    seed : None, optional\n",
    "        Random seed for reproducibility\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        Imputed data frame\n",
    "    \"\"\"\n",
    "    # Copy data frame\n",
    "    imp = data.copy()\n",
    "    \n",
    "    # Set random seed for reproducibility\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Iterate over all variables in the data frame\n",
    "    for c in data.columns:\n",
    "        # Find rows to be imputed and number of missing observations\n",
    "        mr = data[c].isna()\n",
    "        n = mr.sum()\n",
    "        \n",
    "        # Collect observed data for sampling\n",
    "        obs = data[c].dropna().values\n",
    "        \n",
    "        # Impute using random samples\n",
    "        # We assume that the data is not fully missing but only partially\n",
    "        imp.loc[mr, c] = np.random.choice(obs, size=n, replace=True)\n",
    "        \n",
    "    return imp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30b711ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The following function performs single (not multiple yet) imputation using PMM\n",
    "# which will act as the building block for the MICE implementation later on\n",
    "\n",
    "def ImputePMM(data, missingflag, d=5, k=1e-5, seed=None, targets=None):\n",
    "    \"\"\"\n",
    "    Perform imputation using the predictive mean matching (PMM) method. \n",
    "    If the target variables are not specified, it assumes that all variables \n",
    "    are continuous and can be modelled using the Bayesian linear model.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Pandas DataFrame\n",
    "        Data frame to be imputed\n",
    "    missingflag : Pandas DataFrame\n",
    "        A boolean data frame with the exact same dimension as `data`, with an\n",
    "        indicator that shows if a given observation and variable is missing in\n",
    "        `data`\n",
    "    d : int, optional\n",
    "        Number of donors in the donor set (default = 5)\n",
    "    k : float, optional\n",
    "        Ridge parameter for numerical stability (default = 1e-5)\n",
    "    seed : int, optional\n",
    "        Random seed\n",
    "    targets : list, optional\n",
    "        List of target variables to be imputed (assumed to be continuous)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        Imputed data frame\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Iterate over all columns\n",
    "    if targets is None:\n",
    "        targets = data.columns\n",
    "    for i, c in enumerate(targets):\n",
    "        # Separate out variable to be imputed and predictors - with their respective\n",
    "        # flags\n",
    "        y = data[c]\n",
    "        yflag = missingflag[c]\n",
    "        X = data.drop(c, axis=1)\n",
    "        Xflag = missingflag.drop(c, axis=1)\n",
    "        \n",
    "        # Skip if no missing value\n",
    "        if yflag.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        # Separate out observed and missing\n",
    "        Xobs = X[~yflag].values\n",
    "        Xmis = X[yflag].values\n",
    "        yobs = y[~yflag].values\n",
    "        ymis = y[yflag].values\n",
    "        \n",
    "        # Calculate regression weights (Algorithm 3.1)\n",
    "        S = np.transpose(Xobs) @ Xobs\n",
    "        V = np.linalg.inv(S + k * np.diag(np.diag(S)))\n",
    "        bhat = V @ np.transpose(Xobs) @ yobs\n",
    "        \n",
    "        # Calculate noise variance\n",
    "        df = len(yobs) - Xobs.shape[1]\n",
    "        gdot = np.random.chisquare(df)\n",
    "        res = yobs - Xobs @ bhat\n",
    "        sigdot = np.sqrt(np.transpose(res) @ res / gdot)\n",
    "        \n",
    "        # Draw beta from the posterior distribution\n",
    "        z1 = np.random.normal(size=Xobs.shape[1])\n",
    "        bdot = bhat + sigdot * z1 @ np.linalg.cholesky(V)\n",
    "        \n",
    "        # Calculate the imputed values and overwrite data matrix\n",
    "        # NOTE: This is the Bayesian linear model approach, not PMM\n",
    "        #z2 = np.random.normal(size=len(ymis))\n",
    "        #yimp = Xmis @ bdot + z2 * sigdot\n",
    "        #data.loc[yflag, c] = yimp\n",
    "        \n",
    "        # Calculate distances\n",
    "        eta = np.subtract.outer(np.dot(Xobs, bhat).ravel(), np.dot(Xmis, bdot).ravel())\n",
    "        eta = np.abs(eta)\n",
    "        \n",
    "        # Identify donor sets for each missing value\n",
    "        ind = np.argsort(eta, axis=0)\n",
    "        donorind = ind[:d, :]\n",
    "        \n",
    "        # Draw random donor for each missing value\n",
    "        selectedind = np.random.randint(0, d, size=len(ymis))\n",
    "        selecteddonorind = np.diag(donorind[np.ix_(selectedind, np.arange(len(ymis)))])\n",
    "        yimp = yobs[selecteddonorind]\n",
    "        \n",
    "        # Overwrite data matrix\n",
    "        data.loc[yflag, c] = yimp\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e8fa26e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to calculate statistics of imputed data\n",
    "def getImputedStats(data, missingflag):\n",
    "    # Initialize arrays for mean and SD\n",
    "    mu = np.zeros(data.shape[1])\n",
    "    sigma = np.zeros(data.shape[1])\n",
    "    \n",
    "    for i, c in enumerate(data.columns):\n",
    "        # Extract missing data\n",
    "        miss = data.loc[missingflag[c], c]\n",
    "        \n",
    "        # Get statistics\n",
    "        mu[i] = miss.mean()\n",
    "        sigma[i] = miss.std(ddof=1)\n",
    "    \n",
    "    return mu, sigma\n",
    "\n",
    "# Main function for MICE using PMM\n",
    "def MICEPMM(data, m=10, maxit=5, d=5, k=1e-5, seed=123):\n",
    "    \"\"\"\n",
    "    Implement multivariate imputation by chained equations (MICE) using \n",
    "    predictive mean matching (PMM) method. This function assumes that all\n",
    "    variables are continuous and can be modelled using a Bayesian linear model.\n",
    "    Furthermore, it assumes a fully conditional specification (FCS), which makes\n",
    "    the original MICE framework.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Pandas DataFrame\n",
    "        Data frame to be imputed\n",
    "    m : int, optional\n",
    "        Number of multiply imputed data to be generated (default = 10)\n",
    "    maxit : int, optional\n",
    "        Maximum number of iterations for the MICE algorithm (default = 5)\n",
    "    d : int, optional\n",
    "        Number of donors in the donor set (default = 5)\n",
    "    k : float, optional\n",
    "        Ridge parameter for numerical stability (default = 1e-5)\n",
    "    seed : int, optional\n",
    "        Random seed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Python dictionary with the imputed data (`imp`), missing data flag (`missingflag`),\n",
    "        and the chain statistics (`chainmean` and `chainstd`)\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Create flags for missing value\n",
    "    missingflag = data.isna()\n",
    "    \n",
    "    # Make m copies of the data\n",
    "    imp = []\n",
    "    for _ in range(m):\n",
    "        # Initialize using random sample\n",
    "        imp.append(ImputeRandomSample(data))\n",
    "    \n",
    "    # Initialize chain statistics\n",
    "    chainmean = np.empty((data.shape[1], m, maxit+1))\n",
    "    chainstd = np.empty((data.shape[1], m, maxit+1))\n",
    "    for i in range(m):\n",
    "        chainmean[:, i, 0], chainstd[:, i, 0] = getImputedStats(imp[i], missingflag)\n",
    "    \n",
    "    # Iterate over maxit\n",
    "    for j in tqdm(range(maxit)):\n",
    "        #print(\"Iteration {}\".format(j))\n",
    "        \n",
    "        for i in range(m):\n",
    "            # Impute using PMM\n",
    "            imp[i] = ImputePMM(imp[i], missingflag, d=d, k=k)\n",
    "        \n",
    "            # Calculate updated chain statistics\n",
    "            chainmean[:, i, j+1], chainstd[:, i, j+1] = getImputedStats(imp[i], missingflag)\n",
    "    \n",
    "    # Return multiply imputed data and chain statistics\n",
    "    res = {\n",
    "        \"imp\": imp,\n",
    "        \"missingflag\": missingflag,\n",
    "        \"chainmean\": chainmean,\n",
    "        \"chainstd\": chainstd\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c6834f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to present imputed value across different imputations\n",
    "def getImputedData(res, colname):\n",
    "    \"\"\"\n",
    "    Helper function to get a data frame of imputed values for a given variable\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    res : dict\n",
    "        Python dictionary returned by `MICEPMM`\n",
    "    colname : str\n",
    "        Variable for which the imputed data is to be shown\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        Data frame showing observations with missing data only. Each column represents\n",
    "        the output from each imputation model\n",
    "    \"\"\"\n",
    "    # Retrieve relevant data\n",
    "    implist, missingflag = res[\"imp\"], res[\"missingflag\"]\n",
    "    \n",
    "    # Extract relevant missing flag\n",
    "    yflag = missingflag[colname]\n",
    "    \n",
    "    # Iterate over all imputed data\n",
    "    impcombined = []\n",
    "    for i, data in enumerate(implist):\n",
    "        # Extract imputed values\n",
    "        data = data.loc[yflag]\n",
    "        data = data.rename(columns={colname: colname + str(i)})\n",
    "        impcombined.append(data[colname + str(i)])\n",
    "    \n",
    "    impcombined = pd.concat(impcombined, axis=1)\n",
    "    \n",
    "    return impcombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2667d801",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to visualise the chain statistics\n",
    "def ChainStatsViz(res, maxvar=3):\n",
    "    \"\"\"\n",
    "    Constructs a trace plot of chain statistics based on the `MICEPMM` output\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    res : dict\n",
    "        Python dictionary returned by `MICEPMM`\n",
    "    maxvar : int, optional\n",
    "        Maximum number of variables to be visualized (default = 3). Note that only\n",
    "        variables with missing data will be shown\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    matplotlib.pyplot.figure\n",
    "        Figure showing the trace plots\n",
    "    \"\"\"\n",
    "    # Retrieve chain mean and standard deviation\n",
    "    chainmean, chainstd = res[\"chainmean\"], res[\"chainstd\"]\n",
    "    \n",
    "    # Pick first maxvar variables with missing data\n",
    "    allvars = pd.Series(data.columns.values)\n",
    "    missingvars = data.columns[res[\"missingflag\"].sum() > 0]\n",
    "    if len(missingvars) < maxvar:\n",
    "        maxvar = len(missingvars)\n",
    "    else:\n",
    "        missingvars = missingvars[:maxvar]\n",
    "    missingvarsind = allvars[allvars.isin(missingvars)].index\n",
    "    \n",
    "    # Get number of imputed data\n",
    "    m = len(res[\"imp\"])\n",
    "    \n",
    "    # Placeholder for plotting\n",
    "    fig, axs = plt.subplots(figsize=(8, maxvar*3), ncols=2, nrows=maxvar, \n",
    "                            sharex=True)\n",
    "    cmap = cm.get_cmap(\"jet\", 10) # If m > 10, it will rotate back to start\n",
    "    \n",
    "    # Generate plot for each variable and imputation\n",
    "    for i, idx in enumerate(missingvarsind):\n",
    "        # Plot chain mean\n",
    "        for j in range(m):\n",
    "            axs[i, 0].plot(chainmean[i, j, :], color=cmap(j % 10), alpha=0.7)\n",
    "        axs[i, 0].set_title(\"{}: mean\".format(allvars[idx]))\n",
    "        \n",
    "        # Plot chain SD\n",
    "        for j in range(m):\n",
    "            axs[i, 1].plot(chainstd[i, j, :], color=cmap(j % 10), alpha=0.7)\n",
    "        axs[i, 1].set_title(\"{}: SD\".format(allvars[idx]))\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c71ee48",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "(Note from 3.4.4 of Van Buuren)\n",
    "\"Morris et al. (2014) advise to spend efforts on specifying the imputation model correctly, \n",
    "rather than expecting predictive mean matching to do the work.\"\n",
    "\n",
    "(Note from 3.6.2 of Van Buuren)\n",
    "The logreg, polr and polyreg methods in mice implement option 5.\n",
    "\n",
    "(Note from 3.6.3 of Van Buuren)\n",
    "Imputation of categorical data is more difficult than continuous data. As a rule of thumb, \n",
    "in logistic regression we need at least 10 events per predictor in order to get reasonably \n",
    "stable estimates of the regression coefficients (Van Belle, 2002, p. 87).\n",
    "\n",
    "Next step:\n",
    "1. Implement logreg and polyreg (either bootstrap or using data augmentation)\n",
    "2. Implement tree-based model with XAI\n",
    "3. Consider option to extend PMM using GLM as underlying model\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f2e62db",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for imputation using logistic regression with bootstrap\n",
    "\n",
    "def ImputeLogRegBoot(data, missingflag, d=5, k=1e-5, seed=None, targets=None):\n",
    "    \"\"\"\n",
    "    Perform imputation using the logistic regression method with bootstrapping. \n",
    "    Note that target columns should be specified if not all variables are binary.\n",
    "    Note that this implementation also assumes that the binary variables have\n",
    "    been encoded as 0s and 1s.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Pandas DataFrame\n",
    "        Data frame to be imputed\n",
    "    missingflag : Pandas DataFrame\n",
    "        A boolean data frame with the exact same dimension as `data`, with an\n",
    "        indicator that shows if a given observation and variable is missing in\n",
    "        `data`\n",
    "    d : int, optional\n",
    "        Number of donors in the donor set (default = 5)\n",
    "    k : float, optional\n",
    "        Ridge parameter for numerical stability (default = 1e-5)\n",
    "    seed : int, optional\n",
    "        Random seed\n",
    "    targets : list, optional\n",
    "        Target columns to be imputed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        Imputed data frame\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Iterate over all columns\n",
    "    if targets is None:\n",
    "        targets = data.columns\n",
    "    for i, c in enumerate(targets):\n",
    "        # Separate out variable to be imputed and predictors - with their respective\n",
    "        # flags\n",
    "        y = data[c]\n",
    "        yflag = missingflag[c]\n",
    "        X = data.drop(c, axis=1)\n",
    "        Xflag = missingflag.drop(c, axis=1)\n",
    "        \n",
    "        # Skip if no missing value\n",
    "        if yflag.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        # Separate out observed and missing\n",
    "        Xobs = X[~yflag].values\n",
    "        Xmis = X[yflag].values\n",
    "        yobs = y[~yflag].values\n",
    "        ymis = y[yflag].values\n",
    "        \n",
    "        # Stop process if y is not binary\n",
    "        if yobs.nunique() > 2:\n",
    "            raise ValueError(\"Column {} has {} unique values\".format(c, yobs.nunique()))\n",
    "        \n",
    "        # Resample observed data using bootstrap\n",
    "        resampled_idx = np.random.choice(np.arange(yobs.shape[0]), size=yobs.shape[0], \n",
    "                                         replace=True)\n",
    "        Xobs1 = Xobs[resampled_idx, :]\n",
    "        yobs1 = yobs[resampled_idx, :]\n",
    "        \n",
    "        # Train logistic regression model\n",
    "        Xobs1 = sm.add_constant(Xobs1)\n",
    "        lr_model = sm.Logit(yobs1, Xobs1).fit()\n",
    "        \n",
    "        # Predict probabilities using the fitted model\n",
    "        pmis = lr_model.predict(sm.add_constant(Xmis))\n",
    "        \n",
    "        # Generate imputed binary values based on probabilities\n",
    "        yimp = (np.random.uniform(size=ymis.shape[0]) < pmis).astype(float)\n",
    "        \n",
    "        # Overwrite data matrix\n",
    "        data.loc[yflag, c] = yimp\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a28187",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for imputation using logistic regression with data augmentation\n",
    "\n",
    "def ImputeLogRegAugment(data, missingflag, d=5, k=1e-5, seed=None, targets=None):\n",
    "    \"\"\"\n",
    "    Perform imputation using the logistic regression method with data augmentation\n",
    "    according to White, Daniel, and Royston (2010).\n",
    "    Note that target columns should be specified if not all variables are binary.\n",
    "    Note that this implementation also assumes that the binary variables have\n",
    "    been encoded as 0s and 1s.\n",
    "    A key difference against R implementation is the use of standard binomial\n",
    "    instead of quasibinomial.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Pandas DataFrame\n",
    "        Data frame to be imputed\n",
    "    missingflag : Pandas DataFrame\n",
    "        A boolean data frame with the exact same dimension as `data`, with an\n",
    "        indicator that shows if a given observation and variable is missing in\n",
    "        `data`\n",
    "    d : int, optional\n",
    "        Number of donors in the donor set (default = 5)\n",
    "    k : float, optional\n",
    "        Ridge parameter for numerical stability (default = 1e-5)\n",
    "    seed : None, optional\n",
    "        Random seed\n",
    "    targets : None, optional\n",
    "        Target columns to be imputed\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    Pandas DataFrame\n",
    "        Imputed data frame\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "    \n",
    "    # Iterate over all columns\n",
    "    if targets is None:\n",
    "        targets = data.columns\n",
    "    for i, c in enumerate(targets):\n",
    "        # Separate out variable to be imputed and predictors - with their respective\n",
    "        # flags\n",
    "        y = data[c]\n",
    "        yflag = missingflag[c]\n",
    "        X = data.drop(c, axis=1)\n",
    "        Xflag = missingflag.drop(c, axis=1)\n",
    "        \n",
    "        # Skip if no missing value\n",
    "        if yflag.sum() == 0:\n",
    "            continue\n",
    "        \n",
    "        # Perform data augmentation\n",
    "        Xaug, yaug, Xflagaug, yflagaug = _augment_data(X, y, Xflag, yflag)\n",
    "        \n",
    "        # Separate out observed and missing\n",
    "        Xobs = Xaug[~yflagaug].values\n",
    "        Xmis = Xaug[yflagaug].values\n",
    "        yobs = yaug[~yflagaug].values\n",
    "        ymis = yaug[yflagaug].values\n",
    "        \n",
    "        # Stop process if y is not binary\n",
    "        if yobs.nunique() > 2:\n",
    "            raise ValueError(\"Column {} has {} unique values\".format(c, yobs.nunique()))\n",
    "        \n",
    "        # Train logistic regression model\n",
    "        Xobs = sm.add_constant(Xobs)\n",
    "        lr_model = sm.Logit(yobs, Xobs).fit()\n",
    "        \n",
    "        # Sample betas from (estimated) posterior distribution\n",
    "        cov_unscaled = lr_model.cov_params(scale=False)\n",
    "        cov_sqrt = linalg.cholesky(cov_unscaled, lower=True)\n",
    "        betas = lr_model.params.values\n",
    "        beta_star = betas + np.dot(cov_sqrt, np.random.normal(len(betas)))\n",
    "        \n",
    "        # Predict probabilities using betas\n",
    "        pmis = expit(np.dot(sm.add_constant(Xmis), beta_star))\n",
    "        \n",
    "        # Generate imputed binary values based on probabilities\n",
    "        yimp = (np.random.uniform(size=ymis.shape[0]) < pmis).astype(float)\n",
    "        \n",
    "        # Overwrite data matrix\n",
    "        data.loc[yflag, c] = yimp\n",
    "\n",
    "    return data\n",
    "\n",
    "def _augment_data(X, y, Xflag, yflag):\n",
    "    # Helper function for data augmentation based on White, Daniel, Royston (2010)\n",
    "    \n",
    "    # Get number of categories and number of predictors\n",
    "    p = X.shape[1]\n",
    "    k = y.dropna().nunique()\n",
    "    nr = 2 * p * k\n",
    "    \n",
    "    # Calculate column wise mean and SD, then construct a matrix\n",
    "    mu = X.mean()\n",
    "    sig = X.std(ddof=1) # R implements sample variance by default, but not Python\n",
    "    mu_mtrx = np.tile(mu.values.reshape(1, -1), (nr, 1))\n",
    "    sig_mtrx = np.tile(sig.values.reshape(1, -1), (nr, 1))\n",
    "    \n",
    "    # Create shift matrix and outcome label vector\n",
    "    shift_mtrx = linalg.block_diag(*tuple([[[.5], [-.5]]] * p))\n",
    "    shift_mtrx = np.tile(shift_mtrx, (k, 1))\n",
    "    ynew = np.repeat(np.arange(k), 2 * p)\n",
    "    \n",
    "    # Create augmented data\n",
    "    aug = mu_mtrx + shift_mtrx * sig_mtrx\n",
    "    aug = pd.DataFrame(aug, columns=X.columns)\n",
    "    ynew = pd.Series(ynew)\n",
    "    augflag = pd.DataFrame(np.zeros(nr, ).astype(bool), columns=X.columns)\n",
    "    \n",
    "    # Augment to the original data\n",
    "    Xaug = pd.concat([X, aug], ignore_index=True)\n",
    "    yaug = pd.concat([y, ynew], ignore_index=True)\n",
    "    Xflagaug = pd.concat([Xflag, augflag], ignore_index=True)\n",
    "    yflagaug = pd.concat([yflag, pd.Series(np.zeros(nr).astype(bool))], ignore_index=True)\n",
    "    \n",
    "    return Xaug, yaug, Xflagaug, yflagaug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37717e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function for imputation using multinomial regression with data augmentation\n",
    "# Do this later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54a9f7da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to perform MICE using logistic regression\n",
    "\n",
    "def MICELogReg(data, m=10, maxit=5, d=5, k=1e-5, seed=123, method=\"boot\"):\n",
    "    \"\"\"\n",
    "    Implement multivariate imputation by chained equations (MICE) using \n",
    "    logistic regression method. This function assumes that all\n",
    "    variables are binary and are encoded as 0s and 1s. Two methods of logistic\n",
    "    regression imputation are supported, one based on bootstrap approach and the\n",
    "    other based on Bayesian approach (with data augmentation).\n",
    "    Furthermore, it assumes a fully conditional specification (FCS), which makes\n",
    "    the original MICE framework.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Pandas DataFrame\n",
    "        Data frame to be imputed\n",
    "    m : int, optional\n",
    "        Number of multiply imputed data to be generated (default = 10)\n",
    "    maxit : int, optional\n",
    "        Maximum number of iterations for the MICE algorithm (default = 5)\n",
    "    d : int, optional\n",
    "        Number of donors in the donor set (default = 5)\n",
    "    k : float, optional\n",
    "        Ridge parameter for numerical stability (default = 1e-5)\n",
    "    seed : int, optional\n",
    "        Random seed\n",
    "    method : str, optional\n",
    "        Logistic regression method, \"boot\" for bootstrap approach (default) and\n",
    "        \"bayes\" for Bayesian approach\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Python dictionary with the imputed data (`imp`), missing data flag (`missingflag`),\n",
    "        and the chain statistics (`chainmean` and `chainstd`)\n",
    "    \"\"\"\n",
    "    # Set random seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Create flags for missing value\n",
    "    missingflag = data.isna()\n",
    "    \n",
    "    # Make m copies of the data\n",
    "    imp = []\n",
    "    for _ in range(m):\n",
    "        # Initialize using random sample\n",
    "        imp.append(ImputeRandomSample(data))\n",
    "    \n",
    "    # Initialize chain statistics\n",
    "    chainmean = np.empty((data.shape[1], m, maxit+1))\n",
    "    chainstd = np.empty((data.shape[1], m, maxit+1))\n",
    "    for i in range(m):\n",
    "        chainmean[:, i, 0], chainstd[:, i, 0] = getImputedStats(imp[i], missingflag)\n",
    "    \n",
    "    # Iterate over maxit\n",
    "    for j in tqdm(range(maxit)):\n",
    "        #print(\"Iteration {}\".format(j))\n",
    "        \n",
    "        for i in range(m):\n",
    "            # Impute using appropriate method\n",
    "            if method == \"boot\":\n",
    "                imp[i] = ImputeLogRegBoot(imp[i], missingflag, d=d, k=k)\n",
    "            elif method == \"bayes\":\n",
    "                imp[i] = ImputeLogRegBayes(imp[i], missingflag, d=d, k=k)\n",
    "            else:\n",
    "                raise ValueError(\"Invalid method: {}\".format(method))\n",
    "        \n",
    "            # Calculate updated chain statistics\n",
    "            chainmean[:, i, j+1], chainstd[:, i, j+1] = getImputedStats(imp[i], missingflag)\n",
    "    \n",
    "    # Return multiply imputed data and chain statistics\n",
    "    res = {\n",
    "        \"imp\": imp,\n",
    "        \"missingflag\": missingflag,\n",
    "        \"chainmean\": chainmean,\n",
    "        \"chainstd\": chainstd\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565299ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to perform MICE on multiple data types\n",
    "\n",
    "def MICE(data, targets_cat, targets_num, m=10, maxit=5, d=5, k=1e-5, seed=123, \n",
    "         method_cat=\"boot\", method_num=\"pmm\"):\n",
    "    \"\"\"\n",
    "    Implement multivariate imputation by chained equations (MICE). This function\n",
    "    requires continuous and categorical target variables to be explicitly specified.\n",
    "    Appropriate imputation method will then be applied to each target variable type.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    data : Pandas DataFrame\n",
    "        Data frame to be imputed\n",
    "    targets_cat : list\n",
    "        List of categorical target variables to be imputed. Pass an empty list if\n",
    "        no categorical variable is to be imputed\n",
    "    targets_num : list\n",
    "        List of numeric target variables to be imputed. Pass an empty list if\n",
    "        no numeric variable is to be imputed\n",
    "    m : int, optional\n",
    "        Number of multiply imputed data to be generated (default = 10)\n",
    "    maxit : int, optional\n",
    "        Maximum number of iterations for the MICE algorithm (default = 5)\n",
    "    d : int, optional\n",
    "        Number of donors in the donor set (default = 5)\n",
    "    k : float, optional\n",
    "        Ridge parameter for numerical stability (default = 1e-5)\n",
    "    seed : int, optional\n",
    "        Random seed\n",
    "    method_cat : str, optional\n",
    "        Imputation method for categorical target variables. Supports \"boot\" (default),\n",
    "        \"bayes\", and \"pmm\"\n",
    "    method_num : str, optional\n",
    "        Imputation method for numeric target variables. Only supports \"pmm\" (default)\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict\n",
    "        Python dictionary with the imputed data (`imp`), missing data flag (`missingflag`),\n",
    "        and the chain statistics (`chainmean` and `chainstd`)\n",
    "    \"\"\"\n",
    "    # Check validity of imputation methods\n",
    "    assert method_cat in [\"pmm\", \"boot\", \"bayes\"], \"Invalid method : {}\".format(method_cat)\n",
    "    assert method_num in [\"pmm\"], \"Invalid method: {}\".format(method_num)\n",
    "    \n",
    "    # Set random seed\n",
    "    if seed is not None:\n",
    "        np.random.seed(seed)\n",
    "\n",
    "    # Create flags for missing value\n",
    "    missingflag = data.isna()\n",
    "    \n",
    "    # Make m copies of the data\n",
    "    imp = []\n",
    "    for _ in range(m):\n",
    "        # Initialize using random sample\n",
    "        imp.append(ImputeRandomSample(data))\n",
    "    \n",
    "    # Initialize chain statistics\n",
    "    chainmean = np.empty((data.shape[1], m, maxit+1))\n",
    "    chainstd = np.empty((data.shape[1], m, maxit+1))\n",
    "    for i in range(m):\n",
    "        chainmean[:, i, 0], chainstd[:, i, 0] = getImputedStats(imp[i], missingflag)\n",
    "    \n",
    "    # Define dictionary to map appropriate functions\n",
    "    imputefunc = {\n",
    "        \"pmm\" : ImputePMM,\n",
    "        \"boot\": ImputeLogRegBoot,\n",
    "        \"bayes\": ImputeLogRegBayes,\n",
    "    }\n",
    "    \n",
    "    # Iterate over maxit\n",
    "    for j in tqdm(range(maxit)):\n",
    "        #print(\"Iteration {}\".format(j))\n",
    "        \n",
    "        for i in range(m):\n",
    "            # Impute using appropriate method for each data type\n",
    "            if len(targets_cat) > 0:\n",
    "                imp[i] = imputefunc[method_cat](imp[i], missingflag, d=d, k=k, \n",
    "                                                targets=targets_cat)\n",
    "            if len(targets_num) > 0:\n",
    "                imp[i] = imputefunc[method_num](imp[i], missingflag, d=d, k=k, \n",
    "                                                targets=targets_num)\n",
    "        \n",
    "            # Calculate updated chain statistics\n",
    "            chainmean[:, i, j+1], chainstd[:, i, j+1] = getImputedStats(imp[i], missingflag)\n",
    "    \n",
    "    # Return multiply imputed data and chain statistics\n",
    "    res = {\n",
    "        \"imp\": imp,\n",
    "        \"missingflag\": missingflag,\n",
    "        \"chainmean\": chainmean,\n",
    "        \"chainstd\": chainstd\n",
    "    }\n",
    "    return res"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d028d44e",
   "metadata": {},
   "source": [
    "## Step 2B: Apply multiple imputation on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93402342",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0717ab98",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3eb14a14",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b42316",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a82e5016",
   "metadata": {},
   "source": [
    "## Step 3A: Implement two versions of tree-based models (with XAI) for multiply imputed data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "31358a07",
   "metadata": {},
   "source": [
    "### Method 1: Ensemble method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15960a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to construct dataset for ensemble model training\n",
    "def PrepareEnsembleData(res, outcome):\n",
    "    \"\"\"\n",
    "    Prepare data set for ensemble model training using the output of MICE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    res : dict\n",
    "        Dictionary returned by `MICE()` which should contain the imputed data under `imp`\n",
    "    outcome : str\n",
    "        Outcome variable for the ensemble model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    list\n",
    "        List of multiply imputed covariate matrices\n",
    "    list\n",
    "        List of multiply imputed outcome vectors\n",
    "    \"\"\"\n",
    "    X, y = [], []\n",
    "    for i, df in enumerate(res[\"imp\"]):\n",
    "        y.append(df[outcome])\n",
    "        X.append(df.drop(outcome, axis=1))\n",
    "    return X, y\n",
    "\n",
    "# Main class to implement ensemble model (can be RF or any sklearn classifiers basically)\n",
    "class EnsembleClassifier(ClassifierMixin):\n",
    "    def __init__(component, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        self.comp_model = component\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        self.m = len(X) # number of ensemble models to be constructed\n",
    "        self.components = [copy.deepcopy(self.comp_model)] * m # all models are identical\n",
    "        for i in range(self.m):\n",
    "            self.components[i].fit(X[i], y[i])\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        predicted = np.zeros((X.shape[0], m))\n",
    "        for i in range(self.m):\n",
    "            predicted[:, i] = self.components[i].predict(X)\n",
    "        return stats.mode(predicted, axis=1).mode # most common\n",
    "    \n",
    "    def predict_proba(self, X):\n",
    "        predicted = np.zeros((X.shape[0], m))\n",
    "        for i in range(self.m):\n",
    "            predicted[:, i] = self.components[i].predict_proba(X)[:, 1]\n",
    "        pos_p = predicted.mean(axis=1).reshape(-1, 1)\n",
    "        neg_p = 1 - pos_p\n",
    "        return np.hstack((neg_p, pos_p))\n",
    "    \n",
    "    def predict_log_proba(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return np.log(probs)\n",
    "    \n",
    "    def predict_log_odds(self, X):\n",
    "        probs = self.predict_proba(X)\n",
    "        return np.log(probs[:, 1]) - np.log(probs[:, 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04f1b87d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implement SHAP explainer wrapper for classifiers\n",
    "def CreateSHAPExplainer(model, res, outcome):\n",
    "    ## DOCUMENTATION TO BE ADDED\n",
    "    # Get observed data only for the background distribution\n",
    "    any_missingflag = res[\"missingflag\"].any(axis=1)\n",
    "    Xobs = res[\"imp\"][0].drop(outcome, axis=1).iloc[any_missingflag]\n",
    "    background_data = shap.maskers.Independent(Xobs, max_samples=100)\n",
    "    \n",
    "    # Construct SHAP explainer\n",
    "    explainer = shap.Explainer(model.predict_log_odds, background_data)\n",
    "    \n",
    "    # Calculate SHAP values on the entire observed data\n",
    "    shap_values = explainer(Xobs)\n",
    "    \n",
    "    return explainer, shap_values\n",
    "\n",
    "# Create wrapper for SHAP or partial dependence plot\n",
    "def GenerateDependencePlot(model, res, feature, shap_values, shap=False, ax=None):\n",
    "    ## DOCUMENTATION TO BE ADDED\n",
    "    # Create figure object if needed\n",
    "    if ax is None:\n",
    "        fig, ax = plt.subplots(figsize=(5, 5), ncols=1, nrows=1)\n",
    "    else:\n",
    "        fig = None\n",
    "        \n",
    "    # Get observed data only\n",
    "    any_missingflag = res[\"missingflag\"].any(axis=1)\n",
    "    Xobs = res[\"imp\"][0].drop(outcome, axis=1).iloc[any_missingflag]\n",
    "    \n",
    "    if shap:\n",
    "        # Construct SHAP dependence plot\n",
    "        shap.plots.scatter(\n",
    "            shap_values[:, feature], show=False, colors=shap_values, ax=ax\n",
    "        )\n",
    "    else:\n",
    "        # Construct partial dependence plot\n",
    "        shap.partial_dependence_plot(\n",
    "            feature, model.predict_log_odds, Xobs, model_expected_value=True, \n",
    "            feature_expected_value=True, show=False, ice=False, ax=ax\n",
    "        )\n",
    "    \n",
    "    if fig is None:\n",
    "        return ax\n",
    "    else:\n",
    "        return fig\n",
    "\n",
    "# Create wrapper for beeswarm plot\n",
    "def GenerateBeeswarmPlot(model, res, feature, shap_values, shap=False, ax=None):\n",
    "    fig, ax = shap.plots.beeswarm(shap_values, show=False)\n",
    "    \n",
    "    return fig, ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f90175f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to implement k-fold cross validation on ensemble data\n",
    "\n",
    "def KFoldEnsemble(n_splits, X, y, random_state=None):\n",
    "    ## DOCUMENTATION TO BE ADDED\n",
    "    # Generate k-fold object\n",
    "    kf = KFold(n_splits=n_splits, random_state=random_state, shuffle=True)\n",
    "    \n",
    "    # Get number of multiply imputed data\n",
    "    m = len(X)\n",
    "    \n",
    "    # Iterate over the folds\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X[0])):\n",
    "        # Construct train and test data\n",
    "        X_train, X_test, y_train, y_test = [], [], [], []\n",
    "        for j in range(m):\n",
    "            # SPLIT THE DATA HERE\n",
    "        \n",
    "        # Build model on training data\n",
    "        \n",
    "        # Assess performance metric on test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebccb293",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "931da558",
   "metadata": {},
   "source": [
    "### Method 2: Weighting method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98ba91be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Helper function to construct weighted data for weighting method\n",
    "def PrepareWeightedData(res, outcome):\n",
    "    \"\"\"\n",
    "    Prepare data set for ensemble model training using the output of MICE\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    res : dict\n",
    "        Dictionary returned by `MICE()` which should contain the imputed data under `imp`\n",
    "    outcome : str\n",
    "        Outcome variable for the ensemble model\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        Modified covariate matrices with all observed and imputed observations\n",
    "    pandas.DataFrame\n",
    "        Modified outcome vectors with all observed and imputed observations\n",
    "    numpy.ndarray\n",
    "        Weights for all observations\n",
    "    \"\"\"\n",
    "    # Get number of multiply imputed data\n",
    "    m = len(res[\"imp\"])\n",
    "    \n",
    "    # Extract missing flags\n",
    "    missingflag = res[\"missingflag\"]\n",
    "    any_missingflag = res[\"missingflag\"].any(axis=1)\n",
    "    Nobs = (~any_missingflag).sum()\n",
    "    Nmis = any_missingflag.sum()\n",
    "    \n",
    "    # Placeholder for the dataset and assigned weights\n",
    "    Xs, ys, ws = [], [], []\n",
    "    \n",
    "    # Iterate over multiply imputed data\n",
    "    for i, df in enumerate(res[\"imp\"]):\n",
    "        # Extract covariate and outcome data frames\n",
    "        tempX = df.drop(outcome, axis=1)\n",
    "        tempy = df[outcome]\n",
    "        \n",
    "        if i == 0:\n",
    "            # Use the first dataset to separate out observed and imputed\n",
    "            Xs.append(tempX.iloc[~any_missingflag])\n",
    "            ys.append(tempy.iloc[~any_missingflag])\n",
    "            ws.append(np.ones((Nobs, 1)))\n",
    "        \n",
    "        # Append imputed data only with appropriate weight\n",
    "        Xs.append(tempX.iloc[any_missingflag])\n",
    "        ys.append(tempy.iloc[any_missingflag])\n",
    "        ws.append(np.ones((Nmis, 1)) / m)\n",
    "    \n",
    "    # Merge data together\n",
    "    X = pd.concat(Xs, ignore_index=True)\n",
    "    y = pd.concat(ys, ignore_index=True)\n",
    "    w = np.concatenate(ws)\n",
    "    \n",
    "    return X, y, w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53b43a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wrapper to implement k-fold cross validation on weighted data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d34b9190",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d5c083c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "752ffa92",
   "metadata": {},
   "source": [
    "## Step 3B: Apply tree-based models on multiply imputed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08bc5d21",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d122f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8670bc4a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47326276",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e42c9f5f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
