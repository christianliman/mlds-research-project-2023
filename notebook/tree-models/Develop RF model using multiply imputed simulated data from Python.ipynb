{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "993a32f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import copy\n",
    "import shap\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy.special import expit\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from matplotlib import cm\n",
    "from sklearn.base import TransformerMixin, ClassifierMixin\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              RandomForestRegressor, GradientBoostingRegressor)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (roc_auc_score, f1_score, precision_score, recall_score, \n",
    "                             RocCurveDisplay, PrecisionRecallDisplay, \n",
    "                             mean_squared_error)\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e28486f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modelling functions\n",
    "from ensemble_functions import *\n",
    "from weighting_functions import *\n",
    "from explainer_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "083f15e1",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "### Imputed using MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d64c5da7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose with dataset to load (rpy2 or pure Python)\n",
    "imputed_file = \"imputed.pickle\"\n",
    "boston_path = \"../../data/toy-dataset/boston-processed/\"\n",
    "biopsy_path = \"../../data/toy-dataset/biopsy-processed/\"\n",
    "\n",
    "# Place to store results\n",
    "results_path = \"../../results/metrics/\"\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "figures_path = \"../../results/figures/rf_models_python/\"\n",
    "if not os.path.exists(figures_path):\n",
    "    os.mkdir(figures_path)\n",
    "model_iter_name = \"_pythonimputed_stratifiedkfold\"\n",
    "\n",
    "# Load imputed dataset\n",
    "with open(boston_path + imputed_file, \"rb\") as handle:\n",
    "    boston_imputed = pickle.load(handle)\n",
    "\n",
    "with open(biopsy_path + imputed_file, \"rb\") as handle:\n",
    "    biopsy_imputed = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b361075",
   "metadata": {},
   "source": [
    "### Complete case data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c92eee40",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory for complete case data\n",
    "boston_cc_path = \"../../data/toy-dataset/boston-complete-case/\"\n",
    "biopsy_cc_path = \"../../data/toy-dataset/biopsy-complete-case/\"\n",
    "\n",
    "# Load complete case data\n",
    "props = [10, 20, 30, 40, 50]\n",
    "boston_cc = {}\n",
    "biopsy_cc = {}\n",
    "for p in props:\n",
    "    boston_cc[p] = pd.read_csv(boston_cc_path + \"boston_{}.csv\".format(p))\n",
    "    biopsy_cc[p] = pd.read_csv(biopsy_cc_path + \"biopsy_{}.csv\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "209a3733",
   "metadata": {},
   "source": [
    "## Modelling on `boston` dataset (regression)\n",
    "\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09799bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine covariates and outcome variables\n",
    "bostonyvar = \"medv\"\n",
    "bostonXvars = [\"crim\", \"zn\", \"indus\", \"rm\", \"age\", \"dis\", \"tax\", \"ptratio\", \"black\", \n",
    "               \"lstat\", \"chas\", \"nox\"]\n",
    "\n",
    "# Selected features for model explanation\n",
    "selected_boston = [\"nox\", \"rm\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85eb6c2c",
   "metadata": {},
   "source": [
    "### General model setup (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "dfab7ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation folds\n",
    "n_splits = 5\n",
    "\n",
    "# Set random seed\n",
    "SEED = 2023\n",
    "\n",
    "## For now, we are using the default setup from sklearn\n",
    "basemdl = RandomForestRegressor()\n",
    "basemdlname = \"rf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "df90f90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder table to store performance metrics (RMSE)\n",
    "boston_perf = pd.DataFrame(np.zeros((len(props), 3)), index=props, \n",
    "                           columns=[\"CC\", \"Ensemble\", \"Weighting\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c1629e7",
   "metadata": {},
   "source": [
    "### Complete case data\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7d4013b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:04<00:00,  1.09it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all versions of the data\n",
    "for p in tqdm(props):\n",
    "    # Separate indep and outcome variables\n",
    "    X = boston_cc[p][bostonXvars]\n",
    "    y = boston_cc[p][bostonyvar]\n",
    "    \n",
    "    # Initialise k-fold object\n",
    "    kf = KFold(n_splits=n_splits, random_state=SEED, shuffle=True)\n",
    "    \n",
    "    # Placeholder for predictions to calculate performance metrics\n",
    "    preds = []\n",
    "    \n",
    "    # Iterate over the folds\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        # Get train and test data\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train regressor on training data\n",
    "        rf = copy.deepcopy(basemdl).fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data and store predictions\n",
    "        pred_ = rf.predict(X_test)\n",
    "        preds.append(pd.DataFrame({\"true\": y_test, \"pred\": pred_}))\n",
    "    \n",
    "    # Aggregate predictions and compute RMSE\n",
    "    preds = pd.concat(preds)\n",
    "    rmse = mean_squared_error(preds[\"true\"], preds[\"pred\"], squared=False)\n",
    "    boston_perf.loc[p, \"CC\"] = rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "128da695",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4dc1c837",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 468it [03:48,  1.98it/s]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 412it [03:26,  1.90it/s]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 366it [02:33,  2.25it/s]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 322it [02:27,  2.01it/s]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 263it [01:57,  2.03it/s]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Separate indep and outcome variables\n",
    "    X = boston_cc[p][bostonXvars]\n",
    "    y = boston_cc[p][bostonyvar]\n",
    "    \n",
    "    # Train RF regressor\n",
    "    rf = copy.deepcopy(basemdl).fit(X, y)\n",
    "    \n",
    "    # Create output path for model explanation\n",
    "    expl_path = figures_path + \"boston_cc_{}/\".format(p)\n",
    "    if not os.path.exists(expl_path):\n",
    "        os.mkdir(expl_path)\n",
    "    \n",
    "    # Model explanation\n",
    "    background_data = shap.maskers.Independent(X, max_samples=100)\n",
    "    pred_fn = lambda x: rf.predict(x)\n",
    "    expl = shap.Explainer(pred_fn, background_data)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    shapvals = expl(X)\n",
    "    \n",
    "    # Create SHAP dependence plots for selected features\n",
    "    for c in selected_boston:\n",
    "        f1, ax1 = plt.subplots(figsize=(5, 5), ncols=1, nrows=1)\n",
    "        # shap.dependence_plot(c, shap_values=shapvals, features=X, show=False, ax=ax1)\n",
    "        shap.plots.scatter(shapvals[:, c], show=False, ax=ax1)\n",
    "        f1.tight_layout()\n",
    "        f1.savefig(expl_path + \"dependence_{}.pdf\".format(c))\n",
    "    \n",
    "    # Create beeswarm plot\n",
    "    plt.clf()\n",
    "    _ = shap.plots.beeswarm(shapvals, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(expl_path + \"beeswarm.pdf\")\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c0c438d",
   "metadata": {},
   "source": [
    "### Ensemble approach\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "95908e43",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [01:50<00:00, 22.01s/it]\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for all preds just in case things go wrong\n",
    "all_preds = []\n",
    "\n",
    "# Iterate over all versions of the data\n",
    "for p in tqdm(props):\n",
    "    # Prepare ensemble data\n",
    "    X, y = PrepareEnsembleData(boston_imputed[p], bostonyvar, covars=bostonXvars)\n",
    "    \n",
    "    # Construct base model\n",
    "    # basemdl = RandomForestRegressor()\n",
    "    \n",
    "    # Run K-fold CV\n",
    "    metrics, preds = KFoldEnsemble(n_splits, X, y, \n",
    "                                   boston_imputed[p][\"missingflag\"].any(axis=1), \n",
    "                                   basemdl, classifier=False, random_state=SEED)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_preds.append(preds)\n",
    "    boston_perf.loc[p, \"Ensemble\"] = metrics[\"RMSE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ea9f4f",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "94a3efb4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 468it [1:02:05,  8.00s/it]                               \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 412it [52:36,  7.70s/it]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 366it [46:42,  7.70s/it]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 322it [41:02,  7.69s/it]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 263it [33:27,  7.69s/it]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Prepare ensemble data\n",
    "    X, y = PrepareEnsembleData(boston_imputed[p], bostonyvar, covars=bostonXvars)\n",
    "    \n",
    "    # Construct ensemble model\n",
    "    # basemdl = RandomForestRegressor()\n",
    "    ensemblerf = EnsembleRegressor(basemdl).fit(X, y)\n",
    "    \n",
    "    # Create output path for model explanation\n",
    "    expl_path = figures_path + \"boston_ensemble_{}/\".format(p)\n",
    "    if not os.path.exists(expl_path):\n",
    "        os.mkdir(expl_path)\n",
    "    \n",
    "    # Get complete case data for model explanation\n",
    "    mflag = boston_imputed[p][\"missingflag\"].any(axis=1)\n",
    "    Xobs = X[0][bostonXvars][~mflag]\n",
    "    \n",
    "    # Model explanation\n",
    "    background_data = shap.maskers.Independent(Xobs, max_samples=100)\n",
    "    pred_fn = lambda x: ensemblerf.predict(x)\n",
    "    expl = shap.Explainer(pred_fn, background_data)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    shapvals = expl(Xobs)\n",
    "    \n",
    "    # Create SHAP dependence plots for selected features\n",
    "    for c in selected_boston:\n",
    "        f1, ax1 = plt.subplots(figsize=(5, 5), ncols=1, nrows=1)\n",
    "        # shap.dependence_plot(c, shap_values=shapvals, features=Xobs, show=False, ax=ax1)\n",
    "        shap.plots.scatter(shapvals[:, c], show=False, ax=ax1)\n",
    "        f1.tight_layout()\n",
    "        f1.savefig(expl_path + \"dependence_{}.pdf\".format(c))\n",
    "    \n",
    "    # Create beeswarm plot\n",
    "    plt.clf()\n",
    "    _ = shap.plots.beeswarm(shapvals, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(expl_path + \"beeswarm.pdf\")\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88c3559d",
   "metadata": {},
   "source": [
    "### Weighting approach\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9f60303d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:11<00:00,  2.27s/it]\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for all preds just in case things go wrong\n",
    "all_preds = []\n",
    "\n",
    "# Iterate over all versions of the data\n",
    "for p in tqdm(props):\n",
    "    # Construct base model\n",
    "    # basemdl = RandomForestRegressor()\n",
    "    \n",
    "    # Run K-fold CV\n",
    "    metrics, preds = KFoldWeighted(n_splits, boston_imputed[p], bostonyvar, \n",
    "                                   basemdl, classifier=False, random_state=SEED, \n",
    "                                   covars=bostonXvars)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_preds.append(preds)\n",
    "    boston_perf.loc[p, \"Weighting\"] = metrics[\"RMSE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea4a3886",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "51da59e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Permutation explainer: 468it [03:05,  2.38it/s]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 412it [02:46,  2.33it/s]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 366it [02:29,  2.29it/s]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 322it [02:12,  2.24it/s]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Permutation explainer: 263it [01:47,  2.20it/s]                                 \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Prepare weighted data\n",
    "    X, y, w = PrepareWeightedData(boston_imputed[p], bostonyvar, covars=bostonXvars)\n",
    "    \n",
    "    # Construct weighted model\n",
    "    weightedrf = copy.deepcopy(basemdl).fit(X, y, sample_weight=w)\n",
    "    \n",
    "    # Create output path for model explanation\n",
    "    expl_path = figures_path + \"boston_weighting_{}/\".format(p)\n",
    "    if not os.path.exists(expl_path):\n",
    "        os.mkdir(expl_path)\n",
    "    \n",
    "    # Get complete case data for model explanation\n",
    "    mflag = boston_imputed[p][\"missingflag\"].any(axis=1)\n",
    "    Xobs = boston_imputed[p][\"imp\"][0][bostonXvars][~mflag]\n",
    "    \n",
    "    # Model explanation\n",
    "    background_data = shap.maskers.Independent(Xobs, max_samples=100)\n",
    "    pred_fn = lambda x: weightedrf.predict(x)\n",
    "    expl = shap.Explainer(pred_fn, background_data)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    shapvals = expl(Xobs)\n",
    "    \n",
    "    # Create SHAP dependence plots for selected features\n",
    "    for c in selected_boston:\n",
    "        f1, ax1 = plt.subplots(figsize=(5, 5), ncols=1, nrows=1)\n",
    "        # shap.dependence_plot(c, shap_values=shapvals, features=Xobs, show=False, ax=ax1)\n",
    "        shap.plots.scatter(shapvals[:, c], show=False, ax=ax1)\n",
    "        f1.tight_layout()\n",
    "        f1.savefig(expl_path + \"dependence_{}.pdf\".format(c))\n",
    "    \n",
    "    # Create beeswarm plot\n",
    "    plt.clf()\n",
    "    _ = shap.plots.beeswarm(shapvals, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(expl_path + \"beeswarm.pdf\")\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "752e5a0d",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1be7dcb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CC  Ensemble  Weighting\n",
      "10  3.172781  3.024555   3.144469\n",
      "20  3.171484  2.987382   3.139145\n",
      "30  3.355522  3.107355   3.277915\n",
      "40  3.257154  3.066913   3.360226\n",
      "50  3.797095  3.142602   3.514352\n"
     ]
    }
   ],
   "source": [
    "# Print all RMSEs\n",
    "print(boston_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b4487210",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all RMSEs in CSV\n",
    "boston_perf.to_csv(results_path + \"boston_rmse_{}{}.csv\".format(basemdlname, model_iter_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6129923c",
   "metadata": {},
   "source": [
    "## Modelling on `biopsy` dataset (classification)\n",
    "\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2832d83b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine covariates and outcome variables\n",
    "biopsyyvar = \"class_malignant\"\n",
    "biopsyXvars = [\"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V7\", \"V8\", \"V9\"]\n",
    "\n",
    "# Selected features for model explanation\n",
    "selected_biopsy = [\"V1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d5d52ac",
   "metadata": {},
   "source": [
    "### General model setup (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ed3c0595",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation folds\n",
    "n_splits = 5\n",
    "\n",
    "# Set random seed\n",
    "SEED = 2023\n",
    "\n",
    "# Probability cutoff to compute metrics such as F1 score\n",
    "pred_cutoff = 0.5\n",
    "\n",
    "## For now, we are using the default setup from sklearn\n",
    "basemdl = RandomForestClassifier()\n",
    "basemdlname = \"rf\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f97dc572",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder table to store performance metrics (AUROC and F1)\n",
    "biopsy_auroc = pd.DataFrame(np.zeros((len(props), 3)), index=props, \n",
    "                            columns=[\"CC\", \"Ensemble\", \"Weighting\"])\n",
    "biopsy_f1 = pd.DataFrame(np.zeros((len(props), 3)), index=props, \n",
    "                         columns=[\"CC\", \"Ensemble\", \"Weighting\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7164a867",
   "metadata": {},
   "source": [
    "### Complete case data\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4f18992e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:02<00:00,  1.87it/s]\n"
     ]
    }
   ],
   "source": [
    "# Iterate over all versions of the data\n",
    "for p in tqdm(props):\n",
    "    # Separate indep and outcome variables\n",
    "    X = biopsy_cc[p][biopsyXvars]\n",
    "    y = biopsy_cc[p][biopsyyvar]\n",
    "    \n",
    "    # Initialise k-fold object\n",
    "    kf = KFold(n_splits=n_splits, random_state=SEED, shuffle=True)\n",
    "    \n",
    "    # Placeholder for predictions to calculate performance metrics\n",
    "    preds = []\n",
    "    \n",
    "    # Iterate over the folds\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        # Get train and test data\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train classifier on training data\n",
    "        rf = copy.deepcopy(basemdl).fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data and store predictions\n",
    "        pred_ = rf.predict_proba(X_test)[:, 1]\n",
    "        preds.append(pd.DataFrame({\"true\": y_test, \"pred\": pred_}))\n",
    "    \n",
    "    # Aggregate predictions, compute AUROC and F1 score\n",
    "    preds = pd.concat(preds)\n",
    "    preds[\"pred_labels\"] = preds[\"pred\"] > pred_cutoff\n",
    "    biopsy_auroc.loc[p, \"CC\"] = roc_auc_score(preds[\"true\"], preds[\"pred\"])\n",
    "    biopsy_f1.loc[p, \"CC\"] = f1_score(preds[\"true\"], preds[\"pred_labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a015678c",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "98ec22d5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exact explainer: 643it [00:44, 11.45it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 584it [00:37, 11.46it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 511it [00:29, 11.61it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 433it [00:21, 10.98it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 339it [00:14,  7.81it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Separate indep and outcome variables\n",
    "    X = biopsy_cc[p][biopsyXvars]\n",
    "    y = biopsy_cc[p][biopsyyvar]\n",
    "    \n",
    "    # Train RF classifier\n",
    "    rf = copy.deepcopy(basemdl).fit(X, y)\n",
    "    \n",
    "    # Create output path for model explanation\n",
    "    expl_path = figures_path + \"biopsy_cc_{}/\".format(p)\n",
    "    if not os.path.exists(expl_path):\n",
    "        os.mkdir(expl_path)\n",
    "    \n",
    "    # Model explanation\n",
    "    background_data = shap.maskers.Independent(X, max_samples=100)\n",
    "    pred_fn = lambda x: rf.predict_proba(x)[:, 1]\n",
    "    expl = shap.Explainer(pred_fn, background_data, link=shap.links.logit)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    shapvals = expl(X)\n",
    "    \n",
    "    # Create SHAP dependence plots for selected features\n",
    "    for c in selected_biopsy:\n",
    "        f1, ax1 = plt.subplots(figsize=(5, 5), ncols=1, nrows=1)\n",
    "        # shap.dependence_plot(c, shap_values=shapvals, features=X, show=False, ax=ax1)\n",
    "        shap.plots.scatter(shapvals[:, c], show=False, ax=ax1)\n",
    "        f1.tight_layout()\n",
    "        f1.savefig(expl_path + \"dependence_{}.pdf\".format(c))\n",
    "    \n",
    "    # Create beeswarm plot\n",
    "    plt.clf()\n",
    "    _ = shap.plots.beeswarm(shapvals, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(expl_path + \"beeswarm.pdf\")\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da388d97",
   "metadata": {},
   "source": [
    "### Ensemble approach\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a0681346",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:53<00:00, 10.72s/it]\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for all preds just in case things go wrong\n",
    "all_preds = []\n",
    "\n",
    "# Iterate over all versions of the data\n",
    "for p in tqdm(props):\n",
    "    # Prepare ensemble data\n",
    "    X, y = PrepareEnsembleData(biopsy_imputed[p], biopsyyvar, covars=biopsyXvars)\n",
    "    \n",
    "    # Construct base model\n",
    "    # basemdl = RandomForestClassifier()\n",
    "    \n",
    "    # Run K-fold CV\n",
    "    metrics, preds = KFoldEnsemble(n_splits, X, y, \n",
    "                                   biopsy_imputed[p][\"missingflag\"].any(axis=1), \n",
    "                                   basemdl, classifier=True, random_state=SEED)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_preds.append(preds)\n",
    "    biopsy_auroc.loc[p, \"Ensemble\"] = metrics[\"AUROC\"]\n",
    "    biopsy_f1.loc[p, \"Ensemble\"] = metrics[\"F1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61b18e02",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4bcee2a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exact explainer: 643it [14:04,  1.33s/it]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 584it [12:09,  1.27s/it]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 511it [09:44,  1.16s/it]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 433it [07:30,  1.07s/it]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 339it [05:19,  1.02it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Prepare ensemble data\n",
    "    X, y = PrepareEnsembleData(biopsy_imputed[p], biopsyyvar, covars=biopsyXvars)\n",
    "    \n",
    "    # Construct ensemble model\n",
    "    # basemdl = RandomForestClassifier()\n",
    "    ensemblerf = EnsembleClassifier(basemdl).fit(X, y)\n",
    "    \n",
    "    # Create output path for model explanation\n",
    "    expl_path = figures_path + \"biopsy_ensemble_{}/\".format(p)\n",
    "    if not os.path.exists(expl_path):\n",
    "        os.mkdir(expl_path)\n",
    "    \n",
    "    # Get complete case data for model explanation\n",
    "    mflag = biopsy_imputed[p][\"missingflag\"].any(axis=1)\n",
    "    Xobs = X[0][biopsyXvars][~mflag]\n",
    "    \n",
    "    # Model explanation\n",
    "    background_data = shap.maskers.Independent(Xobs, max_samples=100)\n",
    "    pred_fn = lambda x: ensemblerf.predict_proba(x)[:, 1]\n",
    "    expl = shap.Explainer(pred_fn, background_data, link=shap.links.logit)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    shapvals = expl(Xobs)\n",
    "    \n",
    "    # Create SHAP dependence plots for selected features\n",
    "    for c in selected_biopsy:\n",
    "        f1, ax1 = plt.subplots(figsize=(5, 5), ncols=1, nrows=1)\n",
    "        # shap.dependence_plot(c, shap_values=shapvals, features=Xobs, show=False, ax=ax1)\n",
    "        shap.plots.scatter(shapvals[:, c], show=False, ax=ax1)\n",
    "        f1.tight_layout()\n",
    "        f1.savefig(expl_path + \"dependence_{}.pdf\".format(c))\n",
    "    \n",
    "    # Create beeswarm plot\n",
    "    plt.clf()\n",
    "    _ = shap.plots.beeswarm(shapvals, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(expl_path + \"beeswarm.pdf\")\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19676063",
   "metadata": {},
   "source": [
    "### Weighting approach\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "99b0f5b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████████████████| 5/5 [00:04<00:00,  1.03it/s]\n"
     ]
    }
   ],
   "source": [
    "# Placeholder for all preds just in case things go wrong\n",
    "all_preds = []\n",
    "\n",
    "# Iterate over all versions of the data\n",
    "for p in tqdm(props):\n",
    "    # Construct base model\n",
    "    # basemdl = RandomForestClassifier()\n",
    "    \n",
    "    # Run K-fold CV\n",
    "    metrics, preds = KFoldWeighted(n_splits, biopsy_imputed[p], biopsyyvar, \n",
    "                                   basemdl, classifier=True, random_state=SEED, \n",
    "                                   covars=biopsyXvars)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_preds.append(preds)\n",
    "    biopsy_auroc.loc[p, \"Weighting\"] = metrics[\"AUROC\"]\n",
    "    biopsy_f1.loc[p, \"Weighting\"] = metrics[\"F1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87e8d48c",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bbfbcf68",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exact explainer: 643it [00:45, 11.13it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 584it [00:39, 11.27it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 511it [00:31, 11.10it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 433it [00:26, 10.41it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n",
      "Exact explainer: 339it [00:18,  8.70it/s]                                       \n",
      "No data for colormapping provided via 'c'. Parameters 'vmin', 'vmax' will be ignored\n"
     ]
    }
   ],
   "source": [
    "%matplotlib agg\n",
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Prepare weighted data\n",
    "    X, y, w = PrepareWeightedData(biopsy_imputed[p], biopsyyvar, covars=biopsyXvars)\n",
    "    \n",
    "    # Construct weighted model\n",
    "    weightedrf = copy.deepcopy(basemdl).fit(X, y, sample_weight=w)\n",
    "    \n",
    "    # Create output path for model explanation\n",
    "    expl_path = figures_path + \"biopsy_weighting_{}/\".format(p)\n",
    "    if not os.path.exists(expl_path):\n",
    "        os.mkdir(expl_path)\n",
    "    \n",
    "    # Get complete case data for model explanation\n",
    "    mflag = biopsy_imputed[p][\"missingflag\"].any(axis=1)\n",
    "    Xobs = biopsy_imputed[p][\"imp\"][0][biopsyXvars][~mflag]\n",
    "    \n",
    "    # Model explanation\n",
    "    background_data = shap.maskers.Independent(Xobs, max_samples=100)\n",
    "    pred_fn = lambda x: weightedrf.predict_proba(x)[:, 1]\n",
    "    expl = shap.Explainer(pred_fn, background_data, link=shap.links.logit)\n",
    "    \n",
    "    # Calculate SHAP values\n",
    "    shapvals = expl(Xobs)\n",
    "    \n",
    "    # Create SHAP dependence plots for selected features\n",
    "    for c in selected_biopsy:\n",
    "        f1, ax1 = plt.subplots(figsize=(5, 5), ncols=1, nrows=1)\n",
    "        # shap.dependence_plot(c, shap_values=shapvals, features=Xobs, show=False, ax=ax1)\n",
    "        shap.plots.scatter(shapvals[:, c], show=False, ax=ax1)\n",
    "        f1.tight_layout()\n",
    "        f1.savefig(expl_path + \"dependence_{}.pdf\".format(c))\n",
    "    \n",
    "    # Create beeswarm plot\n",
    "    plt.clf()\n",
    "    _ = shap.plots.beeswarm(shapvals, show=False)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(expl_path + \"beeswarm.pdf\")\n",
    "\n",
    "plt.clf()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97ab0f5d",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "e3692b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CC  Ensemble  Weighting\n",
      "10  0.984677  0.986793   0.986227\n",
      "20  0.984088  0.981155   0.979900\n",
      "30  0.982799  0.982822   0.981836\n",
      "40  0.991333  0.991499   0.987452\n",
      "50  0.994379  0.997022   0.997655\n"
     ]
    }
   ],
   "source": [
    "# Print all AUROCs\n",
    "print(biopsy_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "31d359d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "          CC  Ensemble  Weighting\n",
      "10  0.923469  0.944724   0.942643\n",
      "20  0.907895  0.911475   0.915584\n",
      "30  0.894737  0.923729   0.906780\n",
      "40  0.872483  0.896104   0.904459\n",
      "50  0.909091  0.967742   0.957447\n"
     ]
    }
   ],
   "source": [
    "# Print all F1 scores\n",
    "print(biopsy_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0ad7676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all metrics in CSV\n",
    "biopsy_auroc.to_csv(results_path + \"biopsy_auroc_{}{}.csv\".format(basemdlname, model_iter_name))\n",
    "biopsy_f1.to_csv(results_path + \"biopsy_f1_{}{}.csv\".format(basemdlname, model_iter_name))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
