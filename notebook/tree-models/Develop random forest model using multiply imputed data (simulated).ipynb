{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89be9c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import copy\n",
    "import shap\n",
    "import pickle\n",
    "import os\n",
    "\n",
    "from scipy import linalg\n",
    "from scipy.special import expit\n",
    "from scipy import stats\n",
    "from tqdm import tqdm\n",
    "from matplotlib import cm\n",
    "from sklearn.base import TransformerMixin, ClassifierMixin\n",
    "from sklearn.ensemble import (RandomForestClassifier, GradientBoostingClassifier, \n",
    "                              RandomForestRegressor, GradientBoostingRegressor)\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import (roc_auc_score, f1_score, precision_score, recall_score, \n",
    "                             RocCurveDisplay, PrecisionRecallDisplay, \n",
    "                             mean_squared_error)\n",
    "from pandas.api.types import CategoricalDtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c39232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import modelling functions\n",
    "from ensemble_functions import *\n",
    "from weighting_functions import *\n",
    "from explainer_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12bae83f",
   "metadata": {},
   "source": [
    "## Load dataset\n",
    "\n",
    "### Imputed using MICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d520d760",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose with dataset to load (rpy2 or pure Python)\n",
    "imputed_file = \"imputed.pickle\"\n",
    "boston_path = \"../../data/toy-dataset/boston-processed/\"\n",
    "biopsy_path = \"../../data/toy-dataset/biopsy-processed/\"\n",
    "\n",
    "# Place to store results\n",
    "results_path = \"../../results/metrics/\"\n",
    "if not os.path.exists(results_path):\n",
    "    os.mkdir(results_path)\n",
    "\n",
    "# Load imputed dataset\n",
    "with open(boston_path + imputed_file, \"rb\") as handle:\n",
    "    boston_imputed = pickle.load(handle)\n",
    "\n",
    "with open(biopsy_path + imputed_file, \"rb\") as handle:\n",
    "    biopsy_imputed = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd6b0a32",
   "metadata": {},
   "source": [
    "### Complete case data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b767478e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set directory for complete case data\n",
    "boston_cc_path = \"../../data/toy-dataset/boston-complete-case/\"\n",
    "biopsy_cc_path = \"../../data/toy-dataset/biopsy-complete-case/\"\n",
    "\n",
    "# Load complete case data\n",
    "props = [10, 20, 30, 40, 50]\n",
    "boston_cc = {}\n",
    "biopsy_cc = {}\n",
    "for p in props:\n",
    "    boston_cc[p] = pd.read_csv(boston_cc_path + \"boston_{}.csv\".format(p))\n",
    "    biopsy_cc[p] = pd.read_csv(boston_cc_path + \"biopsy_{}.csv\".format(p))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda4b984",
   "metadata": {},
   "source": [
    "## Modelling on `boston` dataset (regression)\n",
    "\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b04d1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine covariates and outcome variables\n",
    "bostonyvar = \"medv\"\n",
    "bostonXvars = [\"crim\", \"zn\", \"indus\", \"rm\", \"age\", \"dis\", \"tax\", \"ptratio\", \"black\", \n",
    "               \"lstat\", \"chas\", \"nox\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65ffd60",
   "metadata": {},
   "source": [
    "### General model setup (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c7d8779",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation folds\n",
    "n_splits = 5\n",
    "\n",
    "# Set random seed\n",
    "SEED = 2023\n",
    "\n",
    "## For now, we are using the default setup from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a79b0a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder table to store performance metrics (RMSE)\n",
    "boston_perf = pd.DataFrame(np.zeros((len(props), 3)), index=props, \n",
    "                           columns=[\"CC\", \"Ensemble\", \"Weighting\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db29ee9",
   "metadata": {},
   "source": [
    "### Complete case data\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ad1ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all versions of the data\n",
    "for p in tqdm(props):\n",
    "    # Separate indep and outcome variables\n",
    "    X = boston_cc[p][bostonXvars]\n",
    "    y = boston_cc[p][bostonyvar]\n",
    "    \n",
    "    # Initialise k-fold object\n",
    "    kf = KFold(n_splits=n_splits, random_state=SEED, shuffle=True)\n",
    "    \n",
    "    # Placeholder for predictions to calculate performance metrics\n",
    "    preds = []\n",
    "    \n",
    "    # Iterate over the folds\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        # Get train and test data\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train regressor on training data\n",
    "        rf = RandomForestRegressor().fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data and store predictions\n",
    "        pred_ = rf.predict(X_test)\n",
    "        preds.append(pd.DataFrame({\"true\": y_test, \"pred\": pred_}))\n",
    "    \n",
    "    # Aggregate predictions and compute RMSE\n",
    "    preds = pd.concat(preds)\n",
    "    rmse = mean_squared_error(preds[\"true\"], preds[\"pred\"], squared=False)\n",
    "    boston_perf.loc[p, \"CC\"] = rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f355b840",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae72a3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Separate indep and outcome variables\n",
    "    X = boston_cc[p][bostonXvars]\n",
    "    y = boston_cc[p][bostonyvar]\n",
    "    \n",
    "    # Train RF regressor\n",
    "    rf = RandomForestRegressor().fit(X, y)\n",
    "    \n",
    "    # Model explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0ecdce9a",
   "metadata": {},
   "source": [
    "### Ensemble approach\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38b8f6b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for all preds just in case things go wrong\n",
    "all_preds = []\n",
    "\n",
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Prepare ensemble data\n",
    "    X, y = PrepareEnsembleData(boston_imputed[p], bostonyvar, covars=bostonXvars)\n",
    "    \n",
    "    # Construct base model\n",
    "    basemdl = RandomForestRegressor()\n",
    "    \n",
    "    # Run K-fold CV\n",
    "    metrics, preds = KFoldEnsemble(n_splits, X, y, boston_imputed[p][\"missingflag\"], \n",
    "                                   basemdl, classifier=False, random_state=SEED)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_preds.append(preds)\n",
    "    boston_perf.loc[p, \"Ensemble\"] = metrics[\"RMSE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2caeaf45",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a5bd860",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Prepare ensemble data\n",
    "    X, y = PrepareEnsembleData(boston_imputed[p], bostonyvar, covars=bostonXvars)\n",
    "    \n",
    "    # Construct ensemble model\n",
    "    basemdl = RandomForestRegressor()\n",
    "    ensemblerf = EnsembleRegressor(basemdl).fit(X, y)\n",
    "    \n",
    "    # Model explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4273881",
   "metadata": {},
   "source": [
    "### Weighting approach\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ac0eb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for all preds just in case things go wrong\n",
    "all_preds = []\n",
    "\n",
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Construct base model\n",
    "    basemdl = RandomForestRegressor()\n",
    "    \n",
    "    # Run K-fold CV\n",
    "    metrics, preds = KFoldWeighted(n_splits, boston_imputed[p], bostonyvar, \n",
    "                                   basemdl, classifier=False, random_state=SEED, \n",
    "                                   covars=bostonXvars)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_preds.append(preds)\n",
    "    boston_perf.loc[p, \"Weighting\"] = metrics[\"RMSE\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3950597f",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ef34cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Prepare weighted data\n",
    "    X, y, w = PrepareWeightedData(boston_imputed[p], bostonyvar, covars=bostonXvars)\n",
    "    \n",
    "    # Construct weighted model\n",
    "    weightedrf = RandomForestRegressor().fit(X, y, sample_weight=w)\n",
    "    \n",
    "    # Model explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b7e220",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3deac59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all RMSEs\n",
    "print(boston_perf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "492685ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all RMSEs in CSV\n",
    "boston_perf.to_csv(results_path + \"boston_rmse_rf.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bbc7c34",
   "metadata": {},
   "source": [
    "## Modelling on `biopsy` dataset (classification)\n",
    "\n",
    "### Data preparation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49dfb517",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Determine covariates and outcome variables\n",
    "biopsyyvar = \"class_malignant\"\n",
    "biopsyXvars = [\"V1\", \"V2\", \"V3\", \"V4\", \"V5\", \"V7\", \"V8\", \"V9\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a096665b",
   "metadata": {},
   "source": [
    "### General model setup (random forest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7ca6dc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cross-validation folds\n",
    "n_splits = 5\n",
    "\n",
    "# Set random seed\n",
    "SEED = 2023\n",
    "\n",
    "# Probability cutoff to compute metrics such as F1 score\n",
    "pred_cutoff = 0.5\n",
    "\n",
    "## For now, we are using the default setup from sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c2662f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder table to store performance metrics (AUROC and F1)\n",
    "biopsy_auroc = pd.DataFrame(np.zeros((len(props), 3)), index=props, \n",
    "                            columns=[\"CC\", \"Ensemble\", \"Weighting\"])\n",
    "biopsy_f1 = pd.DataFrame(np.zeros((len(props), 3)), index=props, \n",
    "                         columns=[\"CC\", \"Ensemble\", \"Weighting\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55c74edf",
   "metadata": {},
   "source": [
    "### Complete case data\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "071ed705",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Separate indep and outcome variables\n",
    "    X = biopsy_cc[p][biopsyXvars]\n",
    "    y = biopsy_cc[p][biopsyyvar]\n",
    "    \n",
    "    # Initialise k-fold object\n",
    "    kf = KFold(n_splits=n_splits, random_state=SEED, shuffle=True)\n",
    "    \n",
    "    # Placeholder for predictions to calculate performance metrics\n",
    "    preds = []\n",
    "    \n",
    "    # Iterate over the folds\n",
    "    for i, (train_index, test_index) in enumerate(kf.split(X)):\n",
    "        # Get train and test data\n",
    "        X_train, y_train = X.iloc[train_index], y.iloc[train_index]\n",
    "        X_test, y_test = X.iloc[test_index], y.iloc[test_index]\n",
    "        \n",
    "        # Train classifier on training data\n",
    "        rf = RandomForestClassifier().fit(X_train, y_train)\n",
    "        \n",
    "        # Predict on test data and store predictions\n",
    "        pred_ = rf.predict_proba(X_test)[:, 1]\n",
    "        preds.append(pd.DataFrame({\"true\": y_test, \"pred\": pred_}))\n",
    "    \n",
    "    # Aggregate predictions, compute AUROC and F1 score\n",
    "    preds = pd.concat(preds)\n",
    "    preds[\"pred_labels\"] = preds[\"pred\"] > pred_cutoff\n",
    "    biopsy_auroc.loc[p, \"CC\"] = roc_auc_score(preds[\"true\"], preds[\"pred\"])\n",
    "    biopsy_f1.loc[p, \"CC\"] = f1_score(preds[\"true\"], preds[\"pred_labels\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ab33a0b",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cc387f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Separate indep and outcome variables\n",
    "    X = biopsy_cc[p][biopsyXvars]\n",
    "    y = biopsy_cc[p][biopsyyvar]\n",
    "    \n",
    "    # Train RF classifier\n",
    "    rf = RandomForestClassifier().fit(X, y)\n",
    "    \n",
    "    # Model explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e38a9938",
   "metadata": {},
   "source": [
    "### Ensemble approach\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bb112a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for all preds just in case things go wrong\n",
    "all_preds = []\n",
    "\n",
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Prepare ensemble data\n",
    "    X, y = PrepareEnsembleData(biopsy_imputed[p], biopsyyvar, covars=biopsyXvars)\n",
    "    \n",
    "    # Construct base model\n",
    "    basemdl = RandomForestClassifier()\n",
    "    \n",
    "    # Run K-fold CV\n",
    "    metrics, preds = KFoldEnsemble(n_splits, X, y, biopsy_imputed[p][\"missingflag\"], \n",
    "                                   basemdl, classifier=True, random_state=SEED)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_preds.append(preds)\n",
    "    biopsy_auroc.loc[p, \"Ensemble\"] = metrics[\"AUROC\"]\n",
    "    biopsy_f1.loc[p, \"Ensemble\"] = metrics[\"F1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae2852ed",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf4b72d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Prepare ensemble data\n",
    "    X, y = PrepareEnsembleData(biopsy_imputed[p], biopsyyvar, covars=biopsyXvars)\n",
    "    \n",
    "    # Construct ensemble model\n",
    "    basemdl = RandomForestClassifier()\n",
    "    ensemblerf = EnsembleClassifier(basemdl).fit(X, y)\n",
    "    \n",
    "    # Model explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dab2fb99",
   "metadata": {},
   "source": [
    "### Weighting approach\n",
    "\n",
    "#### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77910716",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Placeholder for all preds just in case things go wrong\n",
    "all_preds = []\n",
    "\n",
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Construct base model\n",
    "    basemdl = RandomForestClassifier()\n",
    "    \n",
    "    # Run K-fold CV\n",
    "    metrics, preds = KFoldWeighted(n_splits, biopsy_imputed[p], biopsyyvar, \n",
    "                                   basemdl, classifier=True, random_state=SEED, \n",
    "                                   covars=biopsyXvars)\n",
    "    \n",
    "    # Store metrics\n",
    "    all_preds.append(preds)\n",
    "    biopsy_auroc.loc[p, \"Weighting\"] = metrics[\"AUROC\"]\n",
    "    biopsy_f1.loc[p, \"Weighting\"] = metrics[\"F1\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aef4dfd",
   "metadata": {},
   "source": [
    "#### Full model training and explanation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cac6a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Iterate over all versions of the data\n",
    "for p in props:\n",
    "    # Prepare weighted data\n",
    "    X, y, w = PrepareWeightedData(biopsy_imputed[p], biopsyyvar, covars=biopsyXvars)\n",
    "    \n",
    "    # Construct weighted model\n",
    "    weightedrf = RandomForestClassifier().fit(X, y, sample_weight=w)\n",
    "    \n",
    "    # Model explanation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69dc8022",
   "metadata": {},
   "source": [
    "### Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2369d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all AUROCs\n",
    "print(biopsy_auroc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f74e3f96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print all F1 scores\n",
    "print(biopsy_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fff48094",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save all metrics in CSV\n",
    "biopsy_auroc.to_csv(results_path + \"biopsy_auroc_rf.csv\")\n",
    "biopsy_f1.to_csv(results_path + \"biopsy_f1_rf.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
